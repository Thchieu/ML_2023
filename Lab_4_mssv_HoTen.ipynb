{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thchieu/ML_2023/blob/main/Lab_4_mssv_HoTen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to continous dealing with **Logistic Regression**, **kNN**, and **Decision Tree** alogirthms applied to classification tasks. \n",
        "\n",
        "*   **Deadline: 23:59, 12/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Apply **LogisticRegression** to iris dataset which aims at classifying species of iris based on sepal_length (chiều dài đài hoa), sepal_width, petal_length (chiều dài cánh hoa), petal_width. The species are '**setosa**' '**versicolor**' and '**virginica**'. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "data4 = datasets.load_iris()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# code\n",
        "data4 = datasets.load_iris()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data4.data, data4.target,test_size=0.3)\n",
        "\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(x_train, y_train) \n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "print (\"Accuracy : \", accuracy_score(y_test, y_pred)) \n",
        "\n",
        "print (\"Confusion: \\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print (\"Precision score: \", precision_score(y_test, y_pred, average=\"weighted\"))\n",
        "\n",
        "print (\"Recall score: \", recall_score(y_test, y_pred, average=\"weighted\"))\n",
        "\n",
        "print (\"F1 score: \", f1_score(y_test, y_pred, average=\"weighted\"))\n",
        "\n",
        "print (\"ConfusionMatrixDisplay:\", ConfusionMatrixDisplay.from_predictions(y_test, y_pred))"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "1fc92887-9add-4211-bde1-73747181c2a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.9777777777777777\n",
            "Confusion: \n",
            " [[16  0  0]\n",
            " [ 0 13  1]\n",
            " [ 0  0 15]]\n",
            "Precision score:  0.9791666666666666\n",
            "Recall score:  0.9777777777777777\n",
            "F1 score:  0.977724678083101\n",
            "ConfusionMatrixDisplay: <sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x7f0925e486d0>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "Apply LogisticRegression to **MNIST** dataset (mnist.csv) which aims at classifying handwritten digits. Dataset includes 784 pixels values of images (28x28). \n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "# load the MNIST digits dataset\n",
        "mnist = datasets.load_digits()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "5XTHBWC11dtn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "print(\"Number of images: \", len(mnist.images))\n",
        "print(\"Number of labels: \", len(mnist.target))\n",
        "print(\"Classes: \", mnist.target_names)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "accuracy = clf.score(x_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92fed665-e6b3-46f3-c864-3a848b916f9c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images:  1797\n",
            "Number of labels:  1797\n",
            "Classes:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Accuracy: 0.9694444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Apply another classification algorithm named kNN, which is an instance classifcation model. \n",
        "*  3.1. Perform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "\n",
        "*   3.2. Then compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "Rti2y0Wz2KY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "Tal8tjOn3JIH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "k_range = list(range(1, 30, 2))\n",
        "#k_range = np.array(1, 30, 2)\n",
        "data4 = datasets.load_iris()\n",
        "acls=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "f1=[]\n",
        "\n",
        "for k in k_range:\n",
        "  KNN= KNeighborsClassifier(n_neighbors=k)\n",
        "  KNN.fit(x_train, y_train)\n",
        "  y_pred =KNN.predict(x_test)\n",
        "  acls.append(y_pred)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "lr_accuracy = accuracy_score(y_test, y_pred)\n",
        "lr_precision = precision_score(y_test, y_pred, average=\"micro\")\n",
        "lr_recall = recall_score(y_test, y_pred, average=\"micro\")\n",
        "lr_f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
        "print(\"kNN Metrics:\")\n",
        "for k, accuracy, precision, recall, f1 in knn_metrics:\n",
        "    print(f\"k = {k}: Accuracy = {accuracy:.2f}, Precision = {precision:.2f}, Recall = {recall:.2f}, F1 = {f1:.2f}\")\n",
        "print(f\"\\nLogistic Regression Metrics: Accuracy = {lr_accuracy:.2f}, Precision = {lr_precision:.2f}, Recall = {lr_recall:.2f}, F1 = {lr_f1:.2f}\")\n",
        "#  precision.append(precision_score(y_test,y_pred, np.average='micro'))\n"
      ],
      "metadata": {
        "id": "13LkkfpS2ZUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fcd1e5-ede3-4f22-9026-966213ad5667"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN Metrics:\n",
            "k = 1: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 3: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 5: Accuracy = 0.99, Precision = 0.99, Recall = 0.99, F1 = 0.99\n",
            "k = 7: Accuracy = 0.99, Precision = 0.99, Recall = 0.99, F1 = 0.99\n",
            "k = 9: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 11: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 13: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 15: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 17: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 19: Accuracy = 0.97, Precision = 0.98, Recall = 0.97, F1 = 0.97\n",
            "k = 21: Accuracy = 0.97, Precision = 0.98, Recall = 0.97, F1 = 0.97\n",
            "k = 23: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 25: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 27: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 29: Accuracy = 0.97, Precision = 0.97, Recall = 0.97, F1 = 0.97\n",
            "\n",
            "Logistic Regression Metrics: Accuracy = 0.97, Precision = 0.97, Recall = 0.97, F1 = 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Similar to Task 3, apply kNN algorithm to **mnist** dataset which included in datasets of sklearn API.\n",
        "*  4.1.\tPerform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "*  4.2.\tThen compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the MNIST dataset\n",
        "digits = load_digits()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform kNN algorithm for k = 1, 3, 5, ..., 29\n",
        "k_values = list(range(1, 30, 2))\n",
        "knn_metrics = []\n",
        "for k in k_values:\n",
        "    # Train the kNN model with the given k value\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "    knn_metrics.append((k, accuracy, precision, recall, f1))\n",
        "\n",
        "# Find the best value of k based on the highest f1 score\n",
        "best_k = max(knn_metrics, key=lambda x: x[4])[0]\n",
        "print(f\"Best value of k for kNN: {best_k}\\n\")\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, y_pred)\n",
        "lr_precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "lr_recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "lr_f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "# Print the results for both kNN and Logistic Regression\n",
        "print(\"kNN Metrics:\")\n",
        "for k, accuracy, precision, recall, f1 in knn_metrics:\n",
        "    print(f\"k = {k}: Accuracy = {accuracy:.2f}, Precision = {precision:.2f}, Recall = {recall:.2f}, F1 = {f1:.2f}\")\n",
        "print(f\"\\nLogistic Regression Metrics: Accuracy = {lr_accuracy:.2f}, Precision = {lr_precision:.2f}, Recall = {lr_recall:.2f}, F1 = {lr_f1:.2f}\")"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d23f82-7944-4c9b-9cb7-459500f732af"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value of k for kNN: 7\n",
            "\n",
            "kNN Metrics:\n",
            "k = 1: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 3: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 5: Accuracy = 0.99, Precision = 0.99, Recall = 0.99, F1 = 0.99\n",
            "k = 7: Accuracy = 0.99, Precision = 0.99, Recall = 0.99, F1 = 0.99\n",
            "k = 9: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 11: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 13: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 15: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 17: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 19: Accuracy = 0.97, Precision = 0.98, Recall = 0.97, F1 = 0.97\n",
            "k = 21: Accuracy = 0.97, Precision = 0.98, Recall = 0.97, F1 = 0.97\n",
            "k = 23: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 25: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 27: Accuracy = 0.98, Precision = 0.98, Recall = 0.98, F1 = 0.98\n",
            "k = 29: Accuracy = 0.97, Precision = 0.97, Recall = 0.97, F1 = 0.97\n",
            "\n",
            "Logistic Regression Metrics: Accuracy = 0.97, Precision = 0.97, Recall = 0.97, F1 = 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5. \n",
        "Compare the performance of selected classification algorithms (**Decision Treen, kNN, and Logistic Regression**) to ***spam detection***. The dataset can be accessed from the link: http://archive.ics.uci.edu/ml/datasets/Spambase \n",
        "Attribute Information:\n",
        "The last column of 'spambase.csv denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes: \n",
        "*  48 continuous real [0,100] attributes of type word_freq_WORD \n",
        "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string. **Example**: word_freq_address: percentage of words in the e-mail that match ADDRESS.\n",
        "*  6 continuous real [0,100] attributes of type char_freq_CHAR] \n",
        "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
        "*  1 continuous real [1,...] attribute of type capital_run_length_average \n",
        "= average length of uninterrupted sequences of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_longest \n",
        "= length of longest uninterrupted sequence of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail\n",
        "*  1 nominal {0,1} class attribute of type spam = denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In order to compare the performance of selected algorithms, some common metrics including **accuracy, precision, recall, f1 measures** could be used.\n"
      ],
      "metadata": {
        "id": "MVzSk4l505E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "W_1v_ivR2f6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}